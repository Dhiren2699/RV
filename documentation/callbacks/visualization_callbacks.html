<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>RV.callbacks.visualization_callbacks API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>RV.callbacks.visualization_callbacks</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import math
import collections
import numpy as np

import dash
from dash.dependencies import Input, Output, State

from plotly.graph_objs import Figure
import plotly.express as px
from skimage import io

from helperfunctions.annotation_helperfunctions import merge_intervals, get_annotations, annotations_to_raw, confidence_intervals
from helperfunctions.bad_channel_helperfunctions import get_bad_channels
from helperfunctions.loading_helperfunctions import parse_data_file, parse_model_output_file
from helperfunctions.visualization_helperfunctions import get_EEG_figure, calc_power_spectrum, get_most_prominent_freq, get_power_spectrum_plot, get_EEG_plot
from model.run_model import run_model

import constants as c
import globals


def register_visualization_callbacks(app):
    # Selecting channels to plot callback
    @app.callback(
        [Output(&#39;selected-channels-dropdown&#39;, &#39;value&#39;), Output(&#39;channel-topography&#39;, &#39;selectedData&#39;)],
        [Input(&#39;channel-topography&#39;, &#39;selectedData&#39;), Input(&#39;data-file&#39;, &#39;children&#39;)],
        # Input(&#39;selected-channels-dropdown&#39;, &#39;value&#39;),
        # prevent_initial_call=True
    )
    def _get_selected_channels(selectedData, file_name):
        &#34;&#34;&#34;Retrieves names of selected channels. Triggered when datapoints are selected in channel-topography plot and when new file is loaded.

        Args:
            selectedData (dict): Data from latest selection event.
            file_name (string): File-name.

        Returns:
            tuple(list, dict): List of strings of channels selected for plotting, empty dict to reset selectedData.
        &#34;&#34;&#34;
        # print(json.dumps(selectedData, indent=2))
        selected_channels = []

        if selectedData:
            for selected_channel in selectedData[&#39;points&#39;]:
                # print(selected_channel[&#39;customdata&#39;])
                selected_channels.append(selected_channel[&#39;customdata&#39;])

        return selected_channels, {}

    @app.callback(
        [Output(&#39;left-button&#39;, &#39;disabled&#39;), Output(&#39;right-button&#39;, &#39;disabled&#39;)],
        Input(&#39;EEG-graph&#39;, &#39;figure&#39;),
        State(&#39;segment-size&#39;, &#39;value&#39;), 
        # prevent_initial_call=True
    )
    def _update_arrow_buttons(fig, segment_size):
        &#34;&#34;&#34;Disables/enables arrow-buttons based on position of current segment. Triggered when EEG plot has loaded.

        Args:
            segment_size (int): Segment size of EEG plot.
            fig (plotly.graph_objs.Figure): EEG plot.

        Returns:
            tuple(bool, bool): Whether or not to disable left-arrow button, whether or not to disable right-arrow button.
        &#34;&#34;&#34;
        if segment_size and globals.plotting_data:
            if globals.x0 == -0.5 and not globals.x1 &gt; globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;]:
                return True, False
            elif globals.x1 &gt; globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;]:
                return False, True
            else:
                return False, False
        else:
            return True, True

    @app.callback(
        Output(&#39;preload-data&#39;, &#39;children&#39;),
        Input(&#39;EEG-graph&#39;, &#39;figure&#39;),
        [State(&#39;segment-size&#39;, &#39;value&#39;), State(&#39;use-slider&#39;, &#39;value&#39;)],
        prevent_initial_call=True
    )
    def _preload_plots(fig, segment_size, use_slider):
        &#34;&#34;&#34;Preloads 1 following segment and adds it to globals.preloaded_plots. Triggered when EEG plot has loaded.

        Args:
            fig (plotly.graph_objs.Figure): EEG plot.
            segment_size (int): Segment size of EEG plot.
            use_slider (bool): Whether or not to activate view-slider.
        &#34;&#34;&#34;
        if globals.plotting_data:
            if segment_size:
                print(&#39;Preloading segments...&#39;)
                num_segments = math.ceil(globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;] / segment_size)
                # print(num_segments)
                
                upper_bound = globals.current_plot_index + 2 if globals.current_plot_index + 2 &lt; num_segments else num_segments
                # print(upper_bound)

                globals.preloaded_plots[globals.current_plot_index] = fig

                for segment_index in range(upper_bound):
                    if segment_index not in globals.preloaded_plots:
                        new_x0 = segment_index * segment_size - 0.5
                        new_x1 = segment_size + segment_index * segment_size + 0.5
                        globals.preloaded_plots[segment_index] = get_EEG_plot(globals.plotting_data, new_x0, new_x1, use_slider)
                        # print(segment_index)

    # plot-, redraw-, left-arrow-, and right-arrow-button callback
    @app.callback(
        Output(&#39;EEG-graph&#39;, &#39;figure&#39;),
        [Input(&#39;plot-button&#39;, &#39;n_clicks&#39;), Input(&#39;redraw-button&#39;, &#39;n_clicks&#39;), Input(&#39;left-button&#39;, &#39;n_clicks&#39;), Input(&#39;right-button&#39;, &#39;n_clicks&#39;)],
        [
            State(&#39;data-file&#39;, &#39;children&#39;),
            State(&#39;bad-channels-dropdown&#39;, &#39;value&#39;), State(&#39;selected-channels-dropdown&#39;, &#39;value&#39;),
            State(&#34;high-pass&#34;, &#34;value&#34;), State(&#34;low-pass&#34;, &#34;value&#34;),
            State(&#39;reference-dropdown&#39;, &#39;value&#39;),
            State(&#39;bad-channel-detection-dropdown&#39;, &#39;value&#39;), State(&#34;bad-channel-interpolation&#34;, &#34;value&#34;),
            State(&#34;resample-rate&#34;, &#34;value&#34;), State(&#34;scale&#34;, &#34;value&#34;), State(&#34;channel-offset&#34;, &#34;value&#34;), State(&#39;segment-size&#39;, &#39;value&#39;), State(&#39;use-slider&#39;, &#39;value&#39;),
            State(&#39;model-output-files&#39;, &#39;children&#39;),
            State(&#34;run-model&#34;, &#34;value&#34;), State(&#34;annotate-model&#34;, &#34;value&#34;), State(&#34;model-threshold&#34;, &#34;value&#34;),
        ]
    )
    def _update_EEG_plot(plot_button, redraw_button, left_button, right_button, current_file_name, current_selected_bad_channels, selected_channels,
                            high_pass, low_pass, reference, bad_channel_detection, bad_channel_interpolation,
                            resample_rate, scale, channel_offset, segment_size, use_slider,
                            model_output_files, model_run, model_annotate, model_threshold):
        &#34;&#34;&#34;Generates EEG plot preprocessed with given parameter values. Triggered when plot-, redraw-, left-arrow-, and right-arrow button are clicked.

        Args:
            plot_button (int): Num clicks on plot button.
            redraw_button (int): Num clicks on redraw button.
            left_button (int): Num clicks on left-arrow button.
            right_button (int): Num clicks on right-arrow button.
            current_file_name (string): File-name of loaded EEG recording.
            current_selected_bad_channels (list): List of strings of bad-channel names.
            selected_channels (list): List of strings of channels selected for plotting.
            high_pass (float): Input desired high-pass filter value.
            low_pass (float): Input desired low-pass filter value.
            reference (string): Chosen reference.
            bad_channel_detection (string): Chosen automatic bad-channel detection.
            bad_channel_interpolation (list): List containing 1 if bad-channel interpolation is chosen.
            resample_rate (int): Input desired sampling frequency.
            scale (float): Input desired scaling for data.
            channel_offset (float): Input desired channel offset.
            segment_size (int): Input desired segment size for plots.
            use_slider (bool): Whether or not to activate view-slider.
            model_output_files (list): List of strings of model-output file-names.
            model_run (list): List containing 1 if running integrated model is chosen.
            model_annotate (list): List containing 1 if automatic annotation is chosen.
            model_threshold (float): Input desired confidence threshold over which to automatically annotate.

        Returns:
            plotly.graph_objs.Figure: EEG plot.
        &#34;&#34;&#34;
        button_pressed = [p[&#39;prop_id&#39;] for p in dash.callback_context.triggered][0]

        if &#39;right-button&#39; in button_pressed:
            if segment_size:
                globals.current_plot_index += 1

                globals.x0 += segment_size
                globals.x1 += segment_size
                
                # print(globals.x0, globals.x1)

                if globals.current_plot_index in globals.preloaded_plots:
                    updated_fig = globals.preloaded_plots[globals.current_plot_index]
                else:
                    updated_fig = get_EEG_plot(globals.plotting_data, globals.x0, globals.x1, use_slider=use_slider)

                return updated_fig
        
        elif &#39;left-button&#39; in button_pressed:
            if segment_size:
                globals.current_plot_index -= 1
                
                globals.x0 -= segment_size
                globals.x1 -= segment_size
                
                # print(globals.x0, globals.x1)

                if globals.current_plot_index in globals.preloaded_plots:
                    updated_fig = globals.preloaded_plots[globals.current_plot_index]
                else:
                    updated_fig = get_EEG_plot(globals.plotting_data, globals.x0, globals.x1, use_slider=use_slider)

                return updated_fig

        if plot_button or redraw_button:
            print(&#39;Loading plot...&#39;)
            
            if &#39;plot-button&#39; in button_pressed:
                globals.current_plot_index = 0
                globals.preloaded_plots = {}
                
                globals.x0 = -0.5
                if segment_size:
                    globals.x1 = segment_size + 0.5
                else:
                    globals.x1 = (globals.raw.n_times / globals.raw.info[&#39;sfreq&#39;]) + 0.5

            # If re-drawing, keep current annotations and bad channels
            if &#39;redraw-button&#39; in button_pressed:
                globals.marked_annotations = get_annotations(globals.raw)

                selected_bad_channels = current_selected_bad_channels

            print(&#39;Loading data...&#39;)

            if globals.external_raw and plot_button == 1:
                globals.raw = globals.external_raw.copy()
            elif not globals.external_raw:
                globals.raw = parse_data_file(current_file_name)  # reload data in case preprocessing is changed

            if &#39;redraw-button&#39; in button_pressed:
                print(&#39;Redrawing...&#39;)

                # Use previously selected + loaded bad-channels
                globals.raw.info[&#39;bads&#39;] = selected_bad_channels

                # Keep drawn annotations
                annotations_to_raw(globals.raw, globals.marked_annotations)
            else:
                globals.marked_annotations = get_annotations(globals.raw)

            if model_run:
                raw_model = globals.raw.copy()

            # MNE preprocessing
            print(&#39;Pre-processing data...&#39;)

            # Bandpass-filter
            if (high_pass or low_pass) and not (float(high_pass) == globals.raw.info[&#39;highpass&#39;] and float(low_pass) == globals.raw.info[&#39;lowpass&#39;]):
                # print(high_pass)
                # print(low_pass)
                print(&#39;Applying bandpass-filter&#39;)
                globals.raw.filter(high_pass, low_pass, method=&#39;fir&#39;, fir_window=&#39;blackman&#39;)

            print(globals.raw.info[&#39;bads&#39;])

            # Bad-channel detection
            if bad_channel_detection == &#39;None&#39;:
                print(&#39;No automatic bad-channel detection&#39;)
                bad_channel_detection = None
            elif bad_channel_detection == &#39;Autoreject&#39;:
                print(&#39;Automatic bad-channel detection using AutoReject&#39;)

            if bad_channel_detection and (not (&#39;redraw-button&#39; in button_pressed)):
                print(&#39;Performing automatic bad channel detection&#39;)
                detected_bad_channels = get_bad_channels(globals.raw)
                # print(detected_bad_channels)

                total_bad_channels = globals.raw.info[&#39;bads&#39;]
                for bad_channel in detected_bad_channels:
                    if bad_channel not in total_bad_channels:
                        total_bad_channels.append(bad_channel)

                globals.raw.info[&#39;bads&#39;] = total_bad_channels

                if model_run:
                    raw_model.info[&#39;bads&#39;] = total_bad_channels

            # Re-referencing
            if reference:
                # print(&#39;Reference: {}&#39;.format(reference))
                if reference == &#39;None&#39;:
                    print(&#39;No re-referencing&#39;)
                    reference = None
                elif reference != &#39;average&#39;:
                    reference = [reference]

                if reference:
                    print(&#39;Applying custom reference {}&#39;.format(reference))
                    globals.raw.set_eeg_reference(reference)

            # Bad-channel interpolation
            if bad_channel_interpolation:
                # print(globals.raw.info[&#39;bads&#39;])
                print(&#39;Performing bad-channel interpolation&#39;)
                globals.raw = globals.raw.interpolate_bads(reset_bads=False)

            # Resampling
            globals.viewing_raw = globals.raw.copy()

            if resample_rate and float(resample_rate) != globals.raw.info[&#39;sfreq&#39;]:
                print(&#39;Resample-rate: {}&#39;.format(resample_rate))
                print(&#39;Performing resampling&#39;)
                globals.viewing_raw.resample(resample_rate)
                # timestep = 1 / resample_rate

            print(globals.viewing_raw.info)

            if selected_channels:
                selected_channel_names = selected_channels
                print(selected_channel_names)
            else:
                selected_channel_names = []
                print(&#39;No specific channels selected&#39;)

            if (not (model_output_files or model_run)) and model_annotate:
                print(&#39;No model selected to annotate with&#39;)
                model_annotate = False

            model_output = []
            model_channel_names = []
            model_sample_rate = []
            if model_output_files:
                for model_name in model_output_files:
                    # print(model_name)
                    temp_model_output, temp_channel_names, temp_sample_rate = parse_model_output_file(model_name)
                    model_output.append(temp_model_output)
                    model_channel_names.append(temp_channel_names)
                    model_sample_rate.append(temp_sample_rate)

            if model_run:
                print(&#39;Running model...&#39;)
                run_model_output, run_model_channel_names, run_model_sample_rate = run_model(raw_model, globals.viewing_raw)
                model_output.append(run_model_output)
                model_channel_names.append(run_model_channel_names)
                model_sample_rate.append(run_model_sample_rate)

            # Model annotations
            if model_annotate:
                all_model_annotations = []
                for i, model in enumerate(model_output):
                    if model_sample_rate[i]:
                        model_timestep = 1 / model_sample_rate[i]
                    else:
                        model_timestep = 1 / raw_model.info[&#39;sfreq&#39;]
                    # print(model_timestep)
                    if not model_threshold:
                        model_threshold = 0.5
                    output_intervals = confidence_intervals(model, model_threshold, 1, model_timestep)
                    all_model_annotations = all_model_annotations + output_intervals

                merged_model_annotations = merge_intervals(all_model_annotations)

                all_annotations = globals.marked_annotations + merged_model_annotations
                all_annotations = merge_intervals(all_annotations)

                globals.marked_annotations = all_annotations

                annotations_to_raw(globals.raw, globals.marked_annotations)
                annotations_to_raw(globals.viewing_raw, globals.marked_annotations)

            fig = get_EEG_figure(current_file_name, globals.viewing_raw, selected_channel_names, EEG_scale=scale, channel_offset=channel_offset, model_output=model_output, model_channels=model_channel_names, use_slider=use_slider)

            print(&#39;Figure ready&#39;)
            
            return fig

        # Default plot when app is opened
        else:
            # fig = Figure()  # empty figure
            img = io.imread(c.TITLE_IMAGE_FILE)
            fig = px.imshow(img)
            fig.update_xaxes(showticklabels=False)
            fig.update_yaxes(showticklabels=False)
            fig.update_traces(hovertemplate=None, hoverinfo=&#39;skip&#39;)
            return fig

    # Data selection returning power-spectrum callback
    @app.callback(
        [Output(&#39;selected-data&#39;, &#39;children&#39;), Output(&#39;power-spectrum&#39;, &#39;figure&#39;)],
        [Input(&#39;EEG-graph&#39;, &#39;selectedData&#39;)]
    )
    def _get_selected_power_spectrum(selectedData):
        &#34;&#34;&#34;Calculates frequency with highest power density and power-spectrum plot of selectedData.

        Args:
            selectedData (dict): Data from latest selection event.

        Returns:
            tuple(string, plotly.graph_objs.Figure): String of frequency with highest power density, power-spectrum plot of selectedData.
        &#34;&#34;&#34;
        if not selectedData or (not selectedData[&#39;points&#39;]):
            most_prominent_freq = &#39;-&#39;
            fig = Figure()
        else:
            # print(selectedData)
            # selected_data = []

            trace_number = selectedData[&#39;points&#39;][0][&#39;curveNumber&#39;]
            # print(&#39;First trace: {}&#39;.format(trace_number))

            selected_range = selectedData[&#39;range&#39;]
            print(&#39;Range: {}&#39;.format(selected_range))

            split_dict = collections.defaultdict(list)

            for datapoint in selectedData[&#39;points&#39;]:
                split_dict[datapoint[&#39;curveNumber&#39;]].append(datapoint[&#39;customdata&#39;])

            selected_traces_list = list(split_dict.values())

            sample_rate = globals.viewing_raw.info[&#39;sfreq&#39;]

            all_Pxx_den = []

            for counter, trace in enumerate(selected_traces_list):
                # print(counter)
                f, Pxx_den = calc_power_spectrum(sample_rate, trace)
                all_Pxx_den.append(Pxx_den)

            mean_Pxx_den = np.mean(all_Pxx_den, axis=0)

            most_prominent_freq = get_most_prominent_freq(f, mean_Pxx_den)
            most_prominent_freq = round(most_prominent_freq, 2)

            fig = get_power_spectrum_plot(f, mean_Pxx_den)

        return (str(most_prominent_freq) + &#39; Hz&#39;), fig

    # Clicking on data callback
    @app.callback(
        Output(&#39;click-data&#39;, &#39;children&#39;),
        Input(&#39;EEG-graph&#39;, &#39;clickData&#39;),
        prevent_initial_call=True
    )
    def _get_click_data(clickData):
        &#34;&#34;&#34;Prints point that was clicked on to terminal for testing.

        Args:
            clickData (dict): Data from latest click event.
        &#34;&#34;&#34;
        print(&#39;Clicked point: {}&#39;.format(clickData))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="RV.callbacks.visualization_callbacks.register_visualization_callbacks"><code class="name flex">
<span>def <span class="ident">register_visualization_callbacks</span></span>(<span>app)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_visualization_callbacks(app):
    # Selecting channels to plot callback
    @app.callback(
        [Output(&#39;selected-channels-dropdown&#39;, &#39;value&#39;), Output(&#39;channel-topography&#39;, &#39;selectedData&#39;)],
        [Input(&#39;channel-topography&#39;, &#39;selectedData&#39;), Input(&#39;data-file&#39;, &#39;children&#39;)],
        # Input(&#39;selected-channels-dropdown&#39;, &#39;value&#39;),
        # prevent_initial_call=True
    )
    def _get_selected_channels(selectedData, file_name):
        &#34;&#34;&#34;Retrieves names of selected channels. Triggered when datapoints are selected in channel-topography plot and when new file is loaded.

        Args:
            selectedData (dict): Data from latest selection event.
            file_name (string): File-name.

        Returns:
            tuple(list, dict): List of strings of channels selected for plotting, empty dict to reset selectedData.
        &#34;&#34;&#34;
        # print(json.dumps(selectedData, indent=2))
        selected_channels = []

        if selectedData:
            for selected_channel in selectedData[&#39;points&#39;]:
                # print(selected_channel[&#39;customdata&#39;])
                selected_channels.append(selected_channel[&#39;customdata&#39;])

        return selected_channels, {}

    @app.callback(
        [Output(&#39;left-button&#39;, &#39;disabled&#39;), Output(&#39;right-button&#39;, &#39;disabled&#39;)],
        Input(&#39;EEG-graph&#39;, &#39;figure&#39;),
        State(&#39;segment-size&#39;, &#39;value&#39;), 
        # prevent_initial_call=True
    )
    def _update_arrow_buttons(fig, segment_size):
        &#34;&#34;&#34;Disables/enables arrow-buttons based on position of current segment. Triggered when EEG plot has loaded.

        Args:
            segment_size (int): Segment size of EEG plot.
            fig (plotly.graph_objs.Figure): EEG plot.

        Returns:
            tuple(bool, bool): Whether or not to disable left-arrow button, whether or not to disable right-arrow button.
        &#34;&#34;&#34;
        if segment_size and globals.plotting_data:
            if globals.x0 == -0.5 and not globals.x1 &gt; globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;]:
                return True, False
            elif globals.x1 &gt; globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;]:
                return False, True
            else:
                return False, False
        else:
            return True, True

    @app.callback(
        Output(&#39;preload-data&#39;, &#39;children&#39;),
        Input(&#39;EEG-graph&#39;, &#39;figure&#39;),
        [State(&#39;segment-size&#39;, &#39;value&#39;), State(&#39;use-slider&#39;, &#39;value&#39;)],
        prevent_initial_call=True
    )
    def _preload_plots(fig, segment_size, use_slider):
        &#34;&#34;&#34;Preloads 1 following segment and adds it to globals.preloaded_plots. Triggered when EEG plot has loaded.

        Args:
            fig (plotly.graph_objs.Figure): EEG plot.
            segment_size (int): Segment size of EEG plot.
            use_slider (bool): Whether or not to activate view-slider.
        &#34;&#34;&#34;
        if globals.plotting_data:
            if segment_size:
                print(&#39;Preloading segments...&#39;)
                num_segments = math.ceil(globals.plotting_data[&#39;EEG&#39;][&#39;recording_length&#39;] / segment_size)
                # print(num_segments)
                
                upper_bound = globals.current_plot_index + 2 if globals.current_plot_index + 2 &lt; num_segments else num_segments
                # print(upper_bound)

                globals.preloaded_plots[globals.current_plot_index] = fig

                for segment_index in range(upper_bound):
                    if segment_index not in globals.preloaded_plots:
                        new_x0 = segment_index * segment_size - 0.5
                        new_x1 = segment_size + segment_index * segment_size + 0.5
                        globals.preloaded_plots[segment_index] = get_EEG_plot(globals.plotting_data, new_x0, new_x1, use_slider)
                        # print(segment_index)

    # plot-, redraw-, left-arrow-, and right-arrow-button callback
    @app.callback(
        Output(&#39;EEG-graph&#39;, &#39;figure&#39;),
        [Input(&#39;plot-button&#39;, &#39;n_clicks&#39;), Input(&#39;redraw-button&#39;, &#39;n_clicks&#39;), Input(&#39;left-button&#39;, &#39;n_clicks&#39;), Input(&#39;right-button&#39;, &#39;n_clicks&#39;)],
        [
            State(&#39;data-file&#39;, &#39;children&#39;),
            State(&#39;bad-channels-dropdown&#39;, &#39;value&#39;), State(&#39;selected-channels-dropdown&#39;, &#39;value&#39;),
            State(&#34;high-pass&#34;, &#34;value&#34;), State(&#34;low-pass&#34;, &#34;value&#34;),
            State(&#39;reference-dropdown&#39;, &#39;value&#39;),
            State(&#39;bad-channel-detection-dropdown&#39;, &#39;value&#39;), State(&#34;bad-channel-interpolation&#34;, &#34;value&#34;),
            State(&#34;resample-rate&#34;, &#34;value&#34;), State(&#34;scale&#34;, &#34;value&#34;), State(&#34;channel-offset&#34;, &#34;value&#34;), State(&#39;segment-size&#39;, &#39;value&#39;), State(&#39;use-slider&#39;, &#39;value&#39;),
            State(&#39;model-output-files&#39;, &#39;children&#39;),
            State(&#34;run-model&#34;, &#34;value&#34;), State(&#34;annotate-model&#34;, &#34;value&#34;), State(&#34;model-threshold&#34;, &#34;value&#34;),
        ]
    )
    def _update_EEG_plot(plot_button, redraw_button, left_button, right_button, current_file_name, current_selected_bad_channels, selected_channels,
                            high_pass, low_pass, reference, bad_channel_detection, bad_channel_interpolation,
                            resample_rate, scale, channel_offset, segment_size, use_slider,
                            model_output_files, model_run, model_annotate, model_threshold):
        &#34;&#34;&#34;Generates EEG plot preprocessed with given parameter values. Triggered when plot-, redraw-, left-arrow-, and right-arrow button are clicked.

        Args:
            plot_button (int): Num clicks on plot button.
            redraw_button (int): Num clicks on redraw button.
            left_button (int): Num clicks on left-arrow button.
            right_button (int): Num clicks on right-arrow button.
            current_file_name (string): File-name of loaded EEG recording.
            current_selected_bad_channels (list): List of strings of bad-channel names.
            selected_channels (list): List of strings of channels selected for plotting.
            high_pass (float): Input desired high-pass filter value.
            low_pass (float): Input desired low-pass filter value.
            reference (string): Chosen reference.
            bad_channel_detection (string): Chosen automatic bad-channel detection.
            bad_channel_interpolation (list): List containing 1 if bad-channel interpolation is chosen.
            resample_rate (int): Input desired sampling frequency.
            scale (float): Input desired scaling for data.
            channel_offset (float): Input desired channel offset.
            segment_size (int): Input desired segment size for plots.
            use_slider (bool): Whether or not to activate view-slider.
            model_output_files (list): List of strings of model-output file-names.
            model_run (list): List containing 1 if running integrated model is chosen.
            model_annotate (list): List containing 1 if automatic annotation is chosen.
            model_threshold (float): Input desired confidence threshold over which to automatically annotate.

        Returns:
            plotly.graph_objs.Figure: EEG plot.
        &#34;&#34;&#34;
        button_pressed = [p[&#39;prop_id&#39;] for p in dash.callback_context.triggered][0]

        if &#39;right-button&#39; in button_pressed:
            if segment_size:
                globals.current_plot_index += 1

                globals.x0 += segment_size
                globals.x1 += segment_size
                
                # print(globals.x0, globals.x1)

                if globals.current_plot_index in globals.preloaded_plots:
                    updated_fig = globals.preloaded_plots[globals.current_plot_index]
                else:
                    updated_fig = get_EEG_plot(globals.plotting_data, globals.x0, globals.x1, use_slider=use_slider)

                return updated_fig
        
        elif &#39;left-button&#39; in button_pressed:
            if segment_size:
                globals.current_plot_index -= 1
                
                globals.x0 -= segment_size
                globals.x1 -= segment_size
                
                # print(globals.x0, globals.x1)

                if globals.current_plot_index in globals.preloaded_plots:
                    updated_fig = globals.preloaded_plots[globals.current_plot_index]
                else:
                    updated_fig = get_EEG_plot(globals.plotting_data, globals.x0, globals.x1, use_slider=use_slider)

                return updated_fig

        if plot_button or redraw_button:
            print(&#39;Loading plot...&#39;)
            
            if &#39;plot-button&#39; in button_pressed:
                globals.current_plot_index = 0
                globals.preloaded_plots = {}
                
                globals.x0 = -0.5
                if segment_size:
                    globals.x1 = segment_size + 0.5
                else:
                    globals.x1 = (globals.raw.n_times / globals.raw.info[&#39;sfreq&#39;]) + 0.5

            # If re-drawing, keep current annotations and bad channels
            if &#39;redraw-button&#39; in button_pressed:
                globals.marked_annotations = get_annotations(globals.raw)

                selected_bad_channels = current_selected_bad_channels

            print(&#39;Loading data...&#39;)

            if globals.external_raw and plot_button == 1:
                globals.raw = globals.external_raw.copy()
            elif not globals.external_raw:
                globals.raw = parse_data_file(current_file_name)  # reload data in case preprocessing is changed

            if &#39;redraw-button&#39; in button_pressed:
                print(&#39;Redrawing...&#39;)

                # Use previously selected + loaded bad-channels
                globals.raw.info[&#39;bads&#39;] = selected_bad_channels

                # Keep drawn annotations
                annotations_to_raw(globals.raw, globals.marked_annotations)
            else:
                globals.marked_annotations = get_annotations(globals.raw)

            if model_run:
                raw_model = globals.raw.copy()

            # MNE preprocessing
            print(&#39;Pre-processing data...&#39;)

            # Bandpass-filter
            if (high_pass or low_pass) and not (float(high_pass) == globals.raw.info[&#39;highpass&#39;] and float(low_pass) == globals.raw.info[&#39;lowpass&#39;]):
                # print(high_pass)
                # print(low_pass)
                print(&#39;Applying bandpass-filter&#39;)
                globals.raw.filter(high_pass, low_pass, method=&#39;fir&#39;, fir_window=&#39;blackman&#39;)

            print(globals.raw.info[&#39;bads&#39;])

            # Bad-channel detection
            if bad_channel_detection == &#39;None&#39;:
                print(&#39;No automatic bad-channel detection&#39;)
                bad_channel_detection = None
            elif bad_channel_detection == &#39;Autoreject&#39;:
                print(&#39;Automatic bad-channel detection using AutoReject&#39;)

            if bad_channel_detection and (not (&#39;redraw-button&#39; in button_pressed)):
                print(&#39;Performing automatic bad channel detection&#39;)
                detected_bad_channels = get_bad_channels(globals.raw)
                # print(detected_bad_channels)

                total_bad_channels = globals.raw.info[&#39;bads&#39;]
                for bad_channel in detected_bad_channels:
                    if bad_channel not in total_bad_channels:
                        total_bad_channels.append(bad_channel)

                globals.raw.info[&#39;bads&#39;] = total_bad_channels

                if model_run:
                    raw_model.info[&#39;bads&#39;] = total_bad_channels

            # Re-referencing
            if reference:
                # print(&#39;Reference: {}&#39;.format(reference))
                if reference == &#39;None&#39;:
                    print(&#39;No re-referencing&#39;)
                    reference = None
                elif reference != &#39;average&#39;:
                    reference = [reference]

                if reference:
                    print(&#39;Applying custom reference {}&#39;.format(reference))
                    globals.raw.set_eeg_reference(reference)

            # Bad-channel interpolation
            if bad_channel_interpolation:
                # print(globals.raw.info[&#39;bads&#39;])
                print(&#39;Performing bad-channel interpolation&#39;)
                globals.raw = globals.raw.interpolate_bads(reset_bads=False)

            # Resampling
            globals.viewing_raw = globals.raw.copy()

            if resample_rate and float(resample_rate) != globals.raw.info[&#39;sfreq&#39;]:
                print(&#39;Resample-rate: {}&#39;.format(resample_rate))
                print(&#39;Performing resampling&#39;)
                globals.viewing_raw.resample(resample_rate)
                # timestep = 1 / resample_rate

            print(globals.viewing_raw.info)

            if selected_channels:
                selected_channel_names = selected_channels
                print(selected_channel_names)
            else:
                selected_channel_names = []
                print(&#39;No specific channels selected&#39;)

            if (not (model_output_files or model_run)) and model_annotate:
                print(&#39;No model selected to annotate with&#39;)
                model_annotate = False

            model_output = []
            model_channel_names = []
            model_sample_rate = []
            if model_output_files:
                for model_name in model_output_files:
                    # print(model_name)
                    temp_model_output, temp_channel_names, temp_sample_rate = parse_model_output_file(model_name)
                    model_output.append(temp_model_output)
                    model_channel_names.append(temp_channel_names)
                    model_sample_rate.append(temp_sample_rate)

            if model_run:
                print(&#39;Running model...&#39;)
                run_model_output, run_model_channel_names, run_model_sample_rate = run_model(raw_model, globals.viewing_raw)
                model_output.append(run_model_output)
                model_channel_names.append(run_model_channel_names)
                model_sample_rate.append(run_model_sample_rate)

            # Model annotations
            if model_annotate:
                all_model_annotations = []
                for i, model in enumerate(model_output):
                    if model_sample_rate[i]:
                        model_timestep = 1 / model_sample_rate[i]
                    else:
                        model_timestep = 1 / raw_model.info[&#39;sfreq&#39;]
                    # print(model_timestep)
                    if not model_threshold:
                        model_threshold = 0.5
                    output_intervals = confidence_intervals(model, model_threshold, 1, model_timestep)
                    all_model_annotations = all_model_annotations + output_intervals

                merged_model_annotations = merge_intervals(all_model_annotations)

                all_annotations = globals.marked_annotations + merged_model_annotations
                all_annotations = merge_intervals(all_annotations)

                globals.marked_annotations = all_annotations

                annotations_to_raw(globals.raw, globals.marked_annotations)
                annotations_to_raw(globals.viewing_raw, globals.marked_annotations)

            fig = get_EEG_figure(current_file_name, globals.viewing_raw, selected_channel_names, EEG_scale=scale, channel_offset=channel_offset, model_output=model_output, model_channels=model_channel_names, use_slider=use_slider)

            print(&#39;Figure ready&#39;)
            
            return fig

        # Default plot when app is opened
        else:
            # fig = Figure()  # empty figure
            img = io.imread(c.TITLE_IMAGE_FILE)
            fig = px.imshow(img)
            fig.update_xaxes(showticklabels=False)
            fig.update_yaxes(showticklabels=False)
            fig.update_traces(hovertemplate=None, hoverinfo=&#39;skip&#39;)
            return fig

    # Data selection returning power-spectrum callback
    @app.callback(
        [Output(&#39;selected-data&#39;, &#39;children&#39;), Output(&#39;power-spectrum&#39;, &#39;figure&#39;)],
        [Input(&#39;EEG-graph&#39;, &#39;selectedData&#39;)]
    )
    def _get_selected_power_spectrum(selectedData):
        &#34;&#34;&#34;Calculates frequency with highest power density and power-spectrum plot of selectedData.

        Args:
            selectedData (dict): Data from latest selection event.

        Returns:
            tuple(string, plotly.graph_objs.Figure): String of frequency with highest power density, power-spectrum plot of selectedData.
        &#34;&#34;&#34;
        if not selectedData or (not selectedData[&#39;points&#39;]):
            most_prominent_freq = &#39;-&#39;
            fig = Figure()
        else:
            # print(selectedData)
            # selected_data = []

            trace_number = selectedData[&#39;points&#39;][0][&#39;curveNumber&#39;]
            # print(&#39;First trace: {}&#39;.format(trace_number))

            selected_range = selectedData[&#39;range&#39;]
            print(&#39;Range: {}&#39;.format(selected_range))

            split_dict = collections.defaultdict(list)

            for datapoint in selectedData[&#39;points&#39;]:
                split_dict[datapoint[&#39;curveNumber&#39;]].append(datapoint[&#39;customdata&#39;])

            selected_traces_list = list(split_dict.values())

            sample_rate = globals.viewing_raw.info[&#39;sfreq&#39;]

            all_Pxx_den = []

            for counter, trace in enumerate(selected_traces_list):
                # print(counter)
                f, Pxx_den = calc_power_spectrum(sample_rate, trace)
                all_Pxx_den.append(Pxx_den)

            mean_Pxx_den = np.mean(all_Pxx_den, axis=0)

            most_prominent_freq = get_most_prominent_freq(f, mean_Pxx_den)
            most_prominent_freq = round(most_prominent_freq, 2)

            fig = get_power_spectrum_plot(f, mean_Pxx_den)

        return (str(most_prominent_freq) + &#39; Hz&#39;), fig

    # Clicking on data callback
    @app.callback(
        Output(&#39;click-data&#39;, &#39;children&#39;),
        Input(&#39;EEG-graph&#39;, &#39;clickData&#39;),
        prevent_initial_call=True
    )
    def _get_click_data(clickData):
        &#34;&#34;&#34;Prints point that was clicked on to terminal for testing.

        Args:
            clickData (dict): Data from latest click event.
        &#34;&#34;&#34;
        print(&#39;Clicked point: {}&#39;.format(clickData))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="RV.callbacks" href="index.html">RV.callbacks</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="RV.callbacks.visualization_callbacks.register_visualization_callbacks" href="#RV.callbacks.visualization_callbacks.register_visualization_callbacks">register_visualization_callbacks</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>