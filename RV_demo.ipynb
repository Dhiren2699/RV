{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c96acc",
   "metadata": {},
   "source": [
    "# Robin's Viewer Demo\n",
    "## EEG data loading, visualization, and preprocessing with MNE-Python and Robin's Viewer (RV).\n",
    "\n",
    "<font size=\"3\">Contents:</font> \n",
    "* Load demo EEG recording\n",
    "* Bandpass-filter the signal\n",
    "* Downsample the signal for viewing\n",
    "* Clean the filtered signal\n",
    "    * Mark bad channels in the filtered signal using RV\n",
    "    * Mark transient artifacts using RV (guided by the deep-learning model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9197fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input folder and demo files\n",
    "data_folder = './data'\n",
    "EEG_file_name = \"RV_demo_signal.raw\"\n",
    "montage_file_name = 'GSN129.sfp'\n",
    "\n",
    "# Output folder\n",
    "save_files_folder = './save_files'\n",
    "\n",
    "# File paths\n",
    "EEG_file_path = os.path.join(data_folder, EEG_file_name)\n",
    "montage_file_path = os.path.join(data_folder, montage_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645d6db",
   "metadata": {},
   "source": [
    "### 0. Download example EEG recording\n",
    "<font size=\"3\">In order to run this demo, please download the example data (\"RV_demo_signal.raw\" and \"GSN129.sfp\") from https://www.dropbox.com/sh/6llqont8px1s86b/AADmEONSZqmhFXfl5e7NcB8Ga?dl=0 (also linked to in the **\"README.md\"** file) and store it in the *\"data\"* directory. The cell below checks whether the files are in the right directory.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(EEG_file_path):\n",
    "    print('Example EEG signal not found!')\n",
    "else:\n",
    "    print('Found example EEG signal!')\n",
    "    \n",
    "if not os.path.exists(montage_file_path):\n",
    "    print('Montage file not found!')\n",
    "else:\n",
    "    print('Found montage file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645d6db",
   "metadata": {},
   "source": [
    "### 1. Load a raw EEG recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ce836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demo data by using the read_raw_egi() function from MNE.\n",
    "raw = mne.io.read_raw_egi(EEG_file_path, preload=True, verbose=False)\n",
    "# Channel E129 is Cz and is the reference channel, let's rename\n",
    "raw.rename_channels({'E129':'Cz'})\n",
    "# Drop non-EEG channels\n",
    "raw.drop_channels(['eECR', 'info', 'sECR', 'STI 014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6095db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and set montage\n",
    "montage = mne.channels.read_custom_montage(montage_file_path)\n",
    "raw.set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03421071",
   "metadata": {},
   "source": [
    "### 2. Bandpass- and notch-filter the signal\n",
    "<font size=\"3\">As an example, we will apply a bandpass- (1-45Hz) and notch-filter (50Hz) outside of RV before we load and plot it.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_copy = raw.copy()\n",
    "bandpass_lfreq = 1\n",
    "bandpass_hfreq = 45\n",
    "notch_freq = 50\n",
    "filtered_signal = raw_copy.filter(bandpass_lfreq, bandpass_hfreq, fir_window='hamming', fir_design=\"firwin\", verbose=0)\n",
    "filtered_signal.notch_filter(notch_freq, fir_design=\"firwin\", verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db539e18",
   "metadata": {},
   "source": [
    "### 3. Clean the filtered signal\n",
    "<font size=\"3\">We will demonstrate how to use RV to mark bad channels and transient artifacts.</font>\n",
    "\n",
    "#### Starting RV \n",
    "<font size=\"3\">To start RV, run the cell below. You will see a link where the interactive web application is running. Copy this link into the webbrowser of your choice. The initial screen of RV contains a pop-up window where the EEG data is loaded and all of the preprocessing and visualization settings are defined. This is also where you activate the deep-learning model.</font>\n",
    "\n",
    "<font size=\"3\">To increase the performance of interactive visualization, the data will be downsampled. This can be done using the parameter in the **\"Resampling rate\"** field, the value for which is pre-defined in the following cell. To further speed up the performance, we segment the recording into 30-second segments, which can be changed through the **\"Segments (in sec)\"** field.</font>\n",
    "\n",
    "<font size=\"3\">To display the EEG signal, press the **\"Plot\"** button, which will close the pop-up window and lead you to a loading screen after which the main GUI and the signal will be displayed. Note that pressing the **\"Plot\"** button again will reset your view including all marked bad channels and annotated artifacts.</font>\n",
    "\n",
    "<font size=\"3\">Use the \"->\" and \"<-\" buttons to move to the next or previous 10 seconds, respectively.</font>\n",
    "\n",
    "##### Marking bad channels in RV\n",
    "\n",
    "<font size=\"3\">In the menu bar at the top, there is a dropdown menu which is used to select channels to mark them as \"bad\". When this dropdown menu is clicked, all EEG channels are listed for selection. Additionally, you can type the channels’ names yourself and hence narrow down the selection of options. After having selected bad channels, you will have to redraw the signal (press **\"Redraw\"** button to the right) in order for these channels to be marked in gray and for the **\"Hide/show bad channels\"** button to become active. If the loaded recording already includes marked bad channels, they will automatically be selected in this dropdown menu upon loading.</font>\n",
    "\n",
    "##### Annotate artifacts using RV (guided by a deep-learning model)\n",
    "<font size=\"3\">As a guidance to detect artifacts, you can use the deep-learning model which was trained to detect artifacts in EEG data (Diachenko, M., Houtman, S. J., Juarez-Martinez, E. L., Ramautar, J. R., Weiler, R., Mansvelder, H. D., Bruining, H., Bloem, P., & Linkenkaer-Hansen K. (2022). Improved manual annotation of EEG signals through convolutional neural network guidance. eNeuro. Unpublished manuscript.). It might help you make decisions when annotating the signal. Tick the box \"*run model from run_model.py*\" in the pop-up window when RV is started (**Note**: it may take some time to run). Additionally, you can also choose to automatically annotate the signal by the model by ticking the box \"*Annotate according to model with threshold*\" and typing in an artifact probability threshold (e.g. 0.5, meaning that predictions >= 0.5 will be labeled as artifacts). On inspection, you can deselect marked intervals if you do not agree with the model. Once in the viewer, you can click on \"**Highlight model channels** to see which channels were used by the model to make its predictions. \"</font> \n",
    "\n",
    "<font size=\"3\">Artifacts are best identified by scrolling through the data in segments of 10 seconds while viewing all of the channels. If needed, you can adjust the timeframe from showing the entire plot at once down to merely several milliseconds by clicking and dragging the edges of the slider at the bottom. Scrolling can also be done by dragging-and-dropping with the mouse or trackpad on the channel- or time-axis labels or selecting the 3. button in the taskbar (see below) and then dragging-and-dropping on the plot directly. </font>\n",
    "\n",
    "<font size=\"3\">The taskbar is located at the top right of the plot. From left to right, the following buttons are integrated:</font>\n",
    "1. Take a picture of the (annotated) EEG signal and download it as a .png file.\n",
    "2. Select an area to zoom in on (click-and-drag).\n",
    "3. Move view along the channel- or time-axis, or both simultaneously (click-and-drag).\n",
    "4. Select a segment of the data for which to calculate and display the main underlying frequency, as well as a power spectrum in “Power-spectrum” pop-up window, which can be reopened using the “Power spectrum” button in the menu bar (click-and-drag). It is possible to select all channels or only a few desired ones. The latter can be facilitated via the legend explained in Section 3.3.5.\n",
    "5. (Activated by default) Select a segment of the plot to annotate, which creates a semi-transparent red box spanning the entire vertical axis in view (currently only annotations across all channels are supported) across the selected time interval (click-and-drag). These annotations can be freely adjusted in their position and size, or removed entirely (with button 6.), when clicked on. \n",
    "6. Delete the currently selected annotation.\n",
    "7. Zoom in.\n",
    "8. Zoom out.\n",
    "9. Zoom out as much as necessary to show all channels for the entire duration of the recording (or segment), including all peaks in the data (potentially produced by artifacts). \n",
    "10. Display a ruler from both axes to the datapoint currently hovered on.\n",
    "\n",
    "##### Saving changes\n",
    "\n",
    "<font size=\"3\">After you have finished marking bad channels and annotating artifacts, don't forget to save changes. The save-file will be saved to the \"*save_files*\" directory as defined earlier when you click on the \"**Quit**\" button at the top right. Alternatively, use the **\"Save to\"** button to give the save-file a custom name through the GUI.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RV import run_viewer\n",
    "\n",
    "# sampling frequency to be used for visualizing\n",
    "downsample_artifact_removal_freq = 200\n",
    "segment_size = 30\n",
    "\n",
    "parameters = {'resampling_rate': downsample_artifact_removal_freq, 'segment_size': segment_size}\n",
    "\n",
    "# Run Robin's viewer\n",
    "run_viewer(filtered_signal, os.path.join(save_files_folder, 'demo_signal_marked.fif'), parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name = \"demo_signal_marked.fif\"\n",
    "save_file_path = os.path.join(save_files_folder, save_file_name)\n",
    "# Load the signal\n",
    "marked_signal = mne.io.read_raw_fif(save_file_path, preload=True, verbose='INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd30c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of channels\n",
    "print(\"Number of channels: {}\".format(len(marked_signal.ch_names)))\n",
    "# Bad channels marked\n",
    "print(\"Bad channels: {}\".format(marked_signal.info['bads']))\n",
    "# Annotations\n",
    "print(marked_signal.annotations)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba4d32a63420f0989d825ec62a69823abfa94faa5128b24dc45916cf37022a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('RVenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
